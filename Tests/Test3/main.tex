\documentclass{article} 
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{enumitem}
\graphicspath{./}
\usepackage{mathtools, amssymb, amsthm} % imports amsmath

\author{Daniel Palma}
\date{\today}
\title{Test 3 Notes}

\begin{document}

\maketitle
\newpage

\tableofcontents
\newpage

\section{Change of Variables (Jacobians)}

In one-dimensional calculus we often use a change of variable to simplify an integrals.

A change of variables can also be useful in double integrals. We have already seen one example of this: conversion to polar coordinates. The new variables $r$ and $\theta$ are related to the old variables $x$ and $y$ by the equations 

$$ x = r \cos{\theta} \qquad y = r \sin{\theta} $$

and the change of variables formula can we written as 

$$\iint\limits_{R} f(x,y) \mathrm{d}A = \iint\limits_{S} f(r\cos{\theta}, r\sin{\theta})r \ dr \ d\theta$$

Where $S$ is the region in the $r\theta$-plane that corresponds to the region $R$ in the $xy$-plane

More generally, we consider a change of variables that is given by a \textbf{transformation} $T$ from the $uv$-plane to the $xy$-plane:

$$x = g(u,v) \qquad y = h(u,v)$$

or, as we sometimes write,

$$x = x(u,v) \qquad y = y(u,v)$$

We usually assume that $T$ is a \textbf{$\mathbf{C^1}$ transformation}, which means that $g$ and $h$ have continuous first-order partial derivatives.

A transformation $T$ is really just a function whose domain and range are both subsets of $\mathbb{R}^2$. If $T(u_1, v_1) = (x_1.y_1)$, then the point $(x_1,y_1)$ is called the \textbf{image} of the point $(u_1, v_1)$. If no two points have the same image, $T$ is called \textbf{one-to-one}. 

If $T$ is a one-to-one transformation, then it has an \textbf{inverse transformation $\mathbf{T^-1}$} from the $xy$-plane to the $uv$-plane and it may be possible to solve 

$$x = x(u,v) \qquad y = y(u,v)$$

for $u$ and $v$ in terms of $x$ and $y$:

$$u = G(x,y) \qquad v = H(x,y)$$

\subsection{Jacobian}

The \textbf{Jacobian} of the transformation $T$ is given by $x = g(u,v)$ and $y = h(u,v)$ is 


$$\frac{\partial(x,y)}{\partial(u,v)} = 
\begin{vmatrix}
    \frac{\partial x}{\partial u} & \frac{\partial x}{\partial v} \\[8pt]
    \frac{\partial y}{\partial u} & \frac{\partial y}{\partial v} 
\end{vmatrix} = \frac{\partial x}{\partial u} \frac{\partial y}{\partial v} - \frac{\partial x }{ \partial v} \frac{\partial y}{ \partial u}
$$


\subsection{Change of Variables in a Double Integrals}


Supopse that $T$ is a $C^1$ tranformation whose Jacobian is nonzero and that $T$ maps a region $S$ in the $uv$- plane onto a region $R$ in the $xy$-plane. Supposed that $f$ is continuous on $R$ and that $R$ and $S$ are type I or type II plane regions. Suppose also that $T$ is one-to-one, except perhaps on the boundary of $S$. Then 

$$\iint\limits_{R}f(x,y)\ \mathrm{d}A = \iint\limits_{S}f(x(u,v), y(u,v))\begin{vmatrix}
    \frac{\partial(x,y)}{\partial(u,v)}
\end{vmatrix} \ du \ dv$$

\subsubsection{Triple Integrals}

Lets use the definition of the Jacobian, extend it to three dimensions and find the formula for a triple integral and use it to derive the formula for spherical coordinates.

The Jacobian of $T$ is the following $3 \times 3 $ determinant:

$$\frac{\partial(x,y,z)}{\partial(u,v,w)} = \begin{vmatrix}
    \frac{\partial x}{\partial u} & \frac{\partial x}{\partial v} & \frac{\partial x}{ \partial w} \\[6pt]
    \frac{\partial y}{\partial u} & \frac{\partial y}{ \partial v} & \frac{\partial y}{ \partial w} \\[6pt]
    \frac{\partial z}{ \partial u} & \frac{\partial z }{\partial v} & \frac{\partial z}{ \partial w} 
\end{vmatrix}$$

this gives us the MASSIVE formula lol:

$$\iiint\limits_{R} f(x,y,z) \ \mathrm{d}V = \iiint\limits_{S} f(x(u,v,w), y(u,v,w), z(u,v,w)) \bigg\rvert \frac{\partial(x,y,z)}{\partial(u,v,w)} \bigg\rvert \ du \ dv \ dw$$

now lets use this to find the formula for triple intrgration in spherical coordinates!!!! (i'm losing my fucking mind) 

$$x =  \rho \sin{\phi} \cos{\theta} \qquad y = \rho \sin{\phi} \sin{\theta} \qquad z = \rho \cos{\phi}$$

lets compute this absolute unit of a jacobian 

\begin{align*}
    \frac{\partial(x,y,z)}{\partial(\rho,\theta,\phi)} &= \begin{vmatrix}
    \sin{\phi}\cos{\theta}  & -\rho\sin{\phi}\sin{\theta}  & \rho \cos{\phi} \cos{\theta} \\[6pt]
    \sin{\phi}\sin{\theta}   & \rho \sin{\phi} \cos{\theta} & \rho \cos{\phi}\sin{\theta}  \\[6pt]
    \cos{\phi}  & 0 & - \rho \sin(\phi)    
    \end{vmatrix} \\ 
    & = \cos{\phi} (-\rho^2\sin{\phi}\cos{\phi}\sin^2{\theta} - p^2\sin{\phi}\cos{\phi}\cos^2{\theta}) - \rho\sin{\phi} (\rho \sin^2{\phi}\cos^2{\theta + \rho \sin^2{\phi} \sin^2{\theta}}) \\ 
    & = \text{(This reduces all the way to)}  \ p^2\sin{\phi}  \ \ \text{(lol)} 
\end{align*}

anyways, putting this back into our equation would give us

$$\iiint\limits_{R}f(x,y,z) \ \mathrm{d}V = \iiint\limits_{S} f(\rho\sin{\phi}\cos{\theta}, \rho\sin{\phi}\sin{\theta}, \rho\sin{\phi}) \rho^2 \sin{\phi} \ d\rho \ d\theta \ d\phi$$

lets goo!!!!!!



\newpage
\section{Vector Fields}

\begin{center}
    In general, a vector field is a function whose domain is a set of points in $\mathbb{R}^2$ (or $\mathbb{R}^3$ in three dimensions) is a function $\mathbf{F}$ that assigns to each point $(x,y)$ in $D$ a two-dimensional vector $\mathbf{F}(x,y)$. 
\end{center}

The best way to picture a vector field is to draw the arrow represending the vector $\mathbf{F}(x,y)$ starting at the point $(x,y)$. Of course it's impossible to do this for all points $(x,y)$, but we can gain a reasonable impression of $\mathbf{F}$ by doing it for a few representative points in $D$. since $\mathbf{F}(x,y)$ is a two-dimensional vector, we can write it in terms of its \textbf{component functions} $P$ and $Q$ as follows:

$$\mathbf{F}(x,y) = P(x,y)\hat{i} + Q(x,y) \hat{j} = \langle P(x,y), Q(x,y) \rangle$$

or, for short, $\mathbf{F} = P \ \mathbf{i} + Q \  \mathbf{j}$

Notice that $P$ and $Q$ are scalar functions of two variables and are sometimes called \textbf{scalar fields} to distinguish them from vector fields.

\begin{center}
    Let $E$ be a subset of $\mathbb{R}^3$. a \textbf{vector field on} $\mathbb{R}^3$ is a function \textbf{F} that assigns each point $(x,y,z)$ in $E$ a three-dimensional vector $\mathbf{F}(x,y,z)$.
\end{center}

\subsection{Gradient Fields}

if $f$ is a scalar function of two variables, recall that $\nabla f$ is defined by $\nabla f(x,y) = f_x(x,y)\mathbf{i} + f_y(x,y)\mathbf{j} $
\\ 
\\
Therefore, $\nabla f$ is really a vector field on $\mathbb{R}^2$ and is called a \textbf{gradient vector field}. Likewise, if $f$ is a scalar function of three variables (it extends but im too lazy to type this out).

The length of the gradient vector is the value of the directional derivative of $f$ and closely spaced level curves indicate a steep graph.
\\ 
\\
A vector field $\mathbf{F}$ is called a \textbf{conservative vector field} if it is the gradient of some scalar function, that is, if there exists a function $f$ such that $\mathbf{F} = \nabla f$. in this situation $f$ is called a \textbf{potential function} for \textbf{F}.

Not all vector fields are conservative though!!


\newpage
\section{Line Integrals}

In this section we define an integral that is similar to a single integral except that instead of integrating over an interval $[a,b]$, we integrate over a curve $C$. Such integrals are called \textit{line integrals} (although curve integrals would honestly be a better term imo).

Lets start with a plane curve $C$ given by the parametric equations

$$x = x(t) \quad y = y(t) \quad a \leq t \leq b$$

or, equivalently, by the vector equation $\mathbf{r}(t) = x(t)\mathbf{i} + y(t)\mathbf{j}$, and we assume that $C$ is a smooth curve

nerd shit incoming BUT this means that $\mathbf{r'}$ is continuous and $\mathbf{r}'(t) \neq 0$.

so if we divide tha parameter interval $[a,b]$ into $n$ subintervals $[t_i-1, t_i]$ of equal width and we let $x_i = x(t_i)$ and $y_i = y(t_i)$, then the correesponding points $P_i(x_i,y_i)$ divide $C$ into $n$ subarcs with lengths $\Delta s_1, \Delta s_2, \dots, \Delta s_n$. we can do the blah blah blah riemann sum this is like the 8th time we've seen it so basically we get the limit of that and we get the following \\ 

if $f$ is defined on a smooth curve $C$ given by $x = x(t), y = y(t), a \leq t \leq b$, then the \textbf{line integral of f along c} is 

\begin{equation*}
    \int_C f(x,y) \ ds = \lim_{n \rightarrow \infty} \sum_{i=1}^{n} f(x_i^*, y_i^*) \Delta s_i
\end{equation*}

if the limit exists


but also its this

\begin{equation*}
    \int_C f(x,y) \ ds = \int^b_a f(x(t), y(t)) \ \sqrt{(\frac{dx}{dt})^2 + (\frac{dy}{dt})^2} \  dt
\end{equation*}

when we want to distinguis the original line integral $\int_C f(x,y) \ ds $ from others, we call it the \textbf{line integral with respect to arc length}.

The following formulas say that line integrals with respect to $x$ and $y$ can also be evaluated by expressing everything in terms of $t$: $x = x(t), y = y(t), dx = x'(t)dt, dy = y'(t)dt.$

\begin{equation*}
    \int_C f(x,y) \ dx = \int^b_a f(x(t), y(t)) \ x'(t) dt 
\end{equation*}

\begin{equation*}
    \int_C f(x,y) \ dy = \int^b_a f(x(t), y(t)) \ y'(t) dt
\end{equation*}

it frequently happens that line integrals with respect to x and y occur together, when this happens it's customary to abbreviate by writing 

\begin{equation*}
    \int_C P(x,y) \ dx + \int_C Q(x,y) \ dy = \int_C P(x,y) \ dx + Q(x,y) \ dy
\end{equation*}

when we are setting up a line integral, sometimes the most difficult thing is to think of a parametric representation for a curve whose geometric description is given. In particular, we often need to parameterize a line segment so its useful to remember that a vector representation of a line segment that starts at $\mathbf{r}_0$ and ends at $\mathbf{r}_1$ is given by 

\begin{equation*}
    \mathbf{r}(t) = (1- t) \mathbf{r}_0 + t\mathbf{r}_1 \qquad 0 \leq t \leq 1
\end{equation*}

\subsection{Line Integrals in Space}

We now suppose that $C$ is a smooth space curve given by the parametric equations 

\begin{equation*}
    x = x(t) \quad y = y(t) \quad z = z(t) \quad a \leq t \leq b
\end{equation*}

or by a vector equation $\mathbf{r}(t) = x(t) \mathbf{i} + y(t) \mathbf{j} + z(t) \mathbf{k}$. if $f$ is a function of three variables that is continuous on some region containing $C$, then we define the \textbf{ line integral of $\mathbf{f}$ along $\mathbf{C}$} with respect to arc length in a similar manner to that for plane curves:

\begin{equation*}
    \int_C f(x,y,z) \ ds = \lim_{x \rightarrow \infty} \sum_{i=1}^{n} f(x_i^*, y_i^*, z_i^*) \ \Delta s_i
\end{equation*}

and we then evaluate it as follows

\begin{equation*}
    \int_C f(x,y,z) \ ds = \int_{a}^{b} f(x(t), y(t), z(t)) \sqrt{(\frac{dx}{dt})^2 + (\frac{dy}{dt})^2 + (\frac{dz}{dt})^2} \ dt
\end{equation*}

although, observe that all of these formulas can all be written in a more compact vector notation 

\begin{equation*}
    \int_{a}^{b} f(\mathbf{r}(t)) \rvert \mathbf{r}'(t) \rvert \ dt 
\end{equation*}

for the special case $f(x,y,z) = 1$, we get 

\begin{equation*}
    \int_C dz = \int_{a}^{b} \rvert \mathbf{r}'(t) \rvert \ dt = L 
\end{equation*}

where $L$ is the length of the curve $C$

Line integrals along $C$ with respect to  $x, y, $ and $z$ can also be defined.
\\
Therefore, as with line integrals in the plane, we evaluate line integrals fo the form

\begin{equation*}
    \int_C P(x,y,z) \ dx + Q(x,y,z) \ dy + R(x,y,z) \ dz
\end{equation*}

by expressing everything $(x, y,z,d,dy,dz)$ in terms of the parameter $t$.

\subsection{Line Integrals of Vector Fields}

We define the \textbf{work} $W$ done by the force field \textbf{F} as the limit of the Riemann sums, namely

\begin{equation*}
    W = \int_C \mathbf{F}(x,y,z) \cdot \mathbf{T}(x,y,z) \ dx = \int_C \mathbf{F} \cdot \mathbf{T} \ ds
\end{equation*}

where \textbf{T}$(x,y,z)$ is the unit tangent vector at the point $(x,y,z)$ on $C$.

If the curve $C$ is given by the vector equation $\mathbf{r}(t) = x(t) \mathbf{i} + y(t) \mathbf{j} + z(t) \mathbf{k}$, then $\mathbf{T}(t) = \frac{\mathbf{r}'(t)}{\rvert \mathbf{r}'(t) \rvert}$, so using the equation from before we can rewrite it as 

\begin{equation*}
    W = \int_{a}^{b} \mathbf{F}(\mathbf{r}(t)) \cdot \mathbf{r}'(t) \ dt
\end{equation*}

this integral is often appreviated as $\int_C \mathbf{F} \cdot \ d\mathbf{r} $, therefore we make the following definition for the line integral of any continuous vector field.

Let \textbf{F} be a continuous vector field defined on a smooth curve $C$ given by a vector function $\mathbf{r}(t), a \leq t \leq b$. Then the \textbf{line integral of F along C} is 
\begin{equation*}
    \int_C \mathbf{F} \cdot \ d\mathbf{r} = \int_{a}^{b} \mathbf{F}(\mathbf{r}(t)) \cdot \mathbf{r}'(t) \ dt = \int_C \mathbf{F} \cdot \mathbf{T} \ ds
\end{equation*}

Notice, we can formally write $d \mathbf{r} = \mathbf{r}'(t) \ dt$

Finally, we note the connection between line integrals of vector fields and line integrals of scalar fields. Suppose the vector field \textbf{F} on $\mathbb{R}^3$ is given in component for by the equation $\mathbf{F} = P \mathbf{i} + Q \mathbf{j} + R \mathbf{k} $. we use the definition from before to compute its line integral along $C$: 

\begin{align*}
    \int_C \mathbf{F} \cdot d \mathbf{r} &= \int_{a}^{b} \mathbf{F}(\mathbf{r}(t)) \cdot \mathbf{r}'(t) dt \\
    &= \int_{a}^{b} (P \mathbf{i} + Q \mathbf{j} + R \mathbf{k}) \cdot ( x'(t) \mathbf{i} + y'(t) \mathbf{j} + z'(y) \mathbf{k}) \ dt \\
    &= \int_{a}^{b} [P(x(t), y(t), z(t))x'(t) + Q(x(t), y(t), z(t))y'(t) + R(x(t), y(t), z(t)) z'(t)] \ dt
\end{align*}

but importantly, notice this is actually the same integral from earlier, therefore we have 

\begin{equation*}
    \int_C \mathbf{F} \cdot d \mathbf{r} = \int_C P \ dx + Q \ dy + R \ dz \qquad \text{ where $\mathbf{F} = P  \ \mathbf{i} + Q \ \mathbf{j} + R \ \mathbf{k}$}
\end{equation*}

\newpage
\section{The Fundamental Theorem of Line Integrals}

If we think of the gradient vector $\nabla f$ of a function $f$ of two or three variables as a sort of derivative of $f$, then the following theorem can be regarded as a version of the Fundamental Theorem for line integrals. 
\\

Let $C$ be a smooth curve given by the vector function $\mathbf{r}(t)$, $a \leq t \leq b$. let $f$ be a differentiable function of two or three variables whose gradient vector $\nabla f$ is continuous on $C$. Then
\begin{equation*}
    \int_C \nabla f \cdot d \mathbf{r} = f(\mathbf{r}(b)) - f(\mathbf{r}(a))
\end{equation*}

this says that we can evaluate the line integral of a conservative vector field (the gradient vector field of the potential function $f$) simply by knowing the value of $f$ at the endpoints of $C$. In fact, this says that the line integral of $\nabla f$ is the net change in $f$. if $f$ is a function of two variables and $C$ is a plane curve with initial pint $A(x_1, y_1)$ and terminal point $B(x_2,y_2)$ then the formula from before becomes 

\begin{equation*}
    \int_C \nabla f \cdot d \mathbf{r} = f(x_2,y_2) - f(x_1, y_1)
\end{equation*}

if $f$ is a function of three variables and $C$ is a space curve joining the point $A(x_1, y_1, z_1)$ to the point $B(x_2, y_2, z_2)$, then we have

\begin{equation*}
    \int_C \nabla f \cdot d \mathbf{r} = f(x_2,y_z,z_2) - f(x_1, y_1, z_1)
\end{equation*}

\subsection{Independence of Path}

Suppose $C_1$ and $C_2$ are two piecewise-smooth curves (which are called \textbf{paths}) that have the same initial point $A$ and terminal point $B$. One implication of the theorem from above is that 

\begin{equation*}
    \int_{C_1} \nabla f \cdot d \mathbf{r} = \int_{C_2} \nabla f \cdot d \mathbf{r} 
\end{equation*}

so whenever $\nabla f$ is continuous, the line integral of a \textit{conservative} vector field depends only on the initial point and the terminal point of a curve.

In general, if \textbf{F} is a continuous vector field with domain $D$, we say that the line integral $\int_C \mathbf{F} \cdot d \mathbf{r}$ is \textbf{independent of path} if $\int_{C_1} \mathbf{F} \cdot d \mathbf{r} = \int_{C_2} \nabla f \cdot d \mathbf{r}$ for any two paths $C_1$ and $C_2$ in $D$ that have the same initial points and the same terminal points. With this terminology, we can say that \textit{line integrals of conservative vector fields are independent of path.}

A curve is called \textbf{closed} if its terminal point coincides with its initial point, that is, $\mathbf{r}(b) = \mathbf{r}(a)$.

\begin{center}
    $\int_C \mathbf{F} \cdot d \mathbf{r}$ is independent of path in $D$ if and only if $\int_C \mathbf{F} \cdot d \mathbf{r} = 0$ for every closed path $C$ in $D$. 
\end{center}

\begin{center}
    Suppose $\mathbf{F}$ is a vector field that is continuous on an open connected region $D$. if $\int_C \mathbf{F} \cdot d \mathbf{r}$ is independent of path in $D$, then $\mathbf{F}$ is a conservative vector field on $D$; that is, there exists is a function $f$ such that $\nabla f = \mathbf{F}$. 
\end{center}

\subsection{Conservative Vector Fields}

If $\mathbf{F}(x,y) = P(x,y) \ \mathbf{i}  + Q(x,y) \ \mathbf{j}$ is a conservative vector fiekd, where $P$ and $Q$ have continuous first-order partial derivatives on a domain $D$, then throughout $D$ we have 

\begin{equation*}
    \frac{\partial P}{\partial y} = \frac{\partial Q}{\partial x}
\end{equation*}

a \textbf{simple curve} does not intersect itself anywhere between its end points

a \textbf{simply-connected region} in the plane is a connected region $D$  such that every simple closed curve in $D$ encloses only points that are in $D$.

\begin{center}
    Let $\mathbf{F} = P \ \mathbf{i} + Q \ \mathbf{j}$ be a vector field on an open simply-connected region $D$. Suppose that $P$ and $Q$ have continuous first-order partial derivatives and 

    \begin{equation*}
        \frac{\partial P}{ \partial y} = \frac{\partial Q}{ \partial x} \qquad \text{throughout } D 
    \end{equation*}
\end{center}


\newpage
\section{Green's Theorem}

Green's Theorem gives the relationship between a line integral around a simple closed curve $C$ and a double integral over the plane region $D$ bounded by $C$. In stating Green's theorem, we use the convension that the \textbf{positive orientation} of a simple closed curve $C$ refers to a single \textit{counterclockwise} traversal of $C$. Thus if $C$ is given by the vector function $\mathbf{r}(t)$, $a \leq t \leq b$, then the region $D$ is always on the left as the point $\mathbf{r}(t)$ traverses $C$.
\\

\begin{center}
    \textbf{Green's Theorem} Let $C$ be a positively oriented, piecewise-smooth, simple closed curve in the plane and let $D$ be the region bounded by $C$. If $P$ and $Q$ have continuous partial derivative on an open region that contains $D$, then 

    \begin{equation*}
        \int_C P \ dx + Q \ dy = \iint\limits_{D} (\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y} \ \mathrm{d}A)
    \end{equation*}
\end{center}

Note: the notation 

\begin{equation*}
    \oint_C P \ dx + Q \ dy 
\end{equation*}

is sometimes used to indicate that the line integral is calculated using the positive orientation of the closed curve $C$. Another notation for the positively oriented boundary curve of $D$ is $\partial D$, so the equation in Green's Theorem can be written as 

\begin{equation*}
    \iint\limits_{D}(\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}) \ \mathrm{d}A = \int_{\partial D} P \ dx + Q \ dy
\end{equation*}

Green's Theorem should be regarded as the counterpart of the Fundamental Theorem of Calculus for double integrals. Compare the first equation with the statement of the Funadmental Theorem of Calculus Part 2 in the following equation:

\begin{equation*}
    \int_{a}^{b}F'(x) \ dx = F(b) - F(a)
\end{equation*}

In both cases there is an integral involving derivatives ($F', \partial Q / \partial x, and \partial P / \partial y$) on the left side of the equation. And in both cases the right side involves the values of the original functions ($F, Q,$ and $P$) only on the \textit{boundary} of the domain. (In the one-dimensional case, the domain is an interval $[a,b]$ whose boudnary consists of just two points, $a$ and $b.$)

Green's Theorem is not easy to prove in general, NO SHIT!!!!


\newpage
\section{Curl and Divergence}

In this section we define two operations that can be performed on vector fields and that play a basic role in the applications of vector calculus to fluid flow and electricity and magnetism. Each operation resembles differentiation, but one produces a vector field whereas the other produces a scalar field.

\subsection{Curl}

If $\mathbf{F} = P \ \mathbf{i} + Q \ \mathbf{j} + R \  \mathbf{k}$ is a vector field on $\mathbb{R}^3$ and the partial derivatives of $P$, $Q$, and $R$ all exist, then the curlk of $\mathbf{F}$ is the vector field on $\mathbb{R}^3$ defined by 

\begin{equation*}
    \text{curl} \ \mathbf{F} = (\frac{\partial R}{\partial y} - \frac{\partial Q}{\partial z}) \mathbf{i} + (\frac{\partial P}{\partial z} - \frac{\partial R}{\partial x}) \mathbf{j} + (\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}) \mathbf{k}
\end{equation*}

As an aid to our memory, let's rewrite this equation using operator notation. We introduce the vector differential operator $\nabla$ ("del") as 

\begin{equation*}
    \nabla = \mathbf{i} \frac{\partial}{\partial x} + \mathbf{j} \frac{\partial}{ \partial y} + \mathbf{k} \frac{\partial}{\partial z}
\end{equation*}

If we think of $\nabla$ as a vector with components $\partial/\partial x$, $\partial/\partial y$, $\partial/\partial z$, we can also consider the formal cross product of $\nabla$ with the vector field $\mathbf{F}$ as follows:

\begin{align*}
    \nabla \times \mathbf{F} & = \begin{vmatrix}
        \mathbf{i} & \mathbf{j} & \mathbf{k} \\[6pt]
        \frac{\partial }{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{ \partial z} \\[6pt]
        P & Q & R
    \end{vmatrix} \\
    & = \mathbf{i} \frac{\partial}{\partial x} + \mathbf{j} \frac{\partial}{ \partial y} + \mathbf{k} \frac{\partial}{\partial z} \\
    & = \text{curl} \ \mathbf{F}
\end{align*}

So the easiest way to remember this is by the symbolic expression 

\begin{equation*}
    \text{curl } \ \mathbf{F} = \nabla \times \mathbf{F}
\end{equation*}

Recall that the gradient of a function $f$ of three variables is a vector field on $\mathbb{R}^3$ and so we can compute its curl. The following theorem says that the curl of a gradient vector field is $\mathbf{0}$

If $f$ is a function of three variables that has continuous second order partial derivatives then 

\begin{equation*}
    \text{curl}(\nabla f) = \mathbf{0}
\end{equation*}

Since a conservative vector field is one for which $\mathbf{F} = \nabla f$, we can say this

\begin{center}
    If $\mathbf{F}$ is conservative, then furl $\mathbf{F} = \mathbf{0}$
\end{center}

this gives us a way of verifying that a vector field is not conservative.

\subsection{Divergence}

If $\mathbf{F} = P \ \mathbf{i} + Q \ \mathbf{j} + R \ \mathbf{k} $ is a vector field on $\mathbb{R}^3$ and the partial derivatives of P/x, Q/y and R/z exist, then the \textbf{divergence of F} is the function of three variables defined by 

\begin{equation*}
    div \mathbf{F} = \frac{\partial P}{\partial x} + \frac{\partial Q}{\partial y} + \frac{\partial R}{\partial z}
\end{equation*}

Observe that curl \textbf{F} is a vector field but div \textbf{F} is a scalar field. In terms of the gradient operator $\nabla = (\partial/\partial x) \ \mathbf{i} + (\partial / \partial y) \ \mathbf{j}+ (\partial / \partial z) \ \mathbf{k}$, the divergence of \textbf{F} can be written symbolically as the dot product of $\nabla$ and $\mathbf{F}$:

\begin{equation*}
    \text{div} \  \mathbf{F} = \nabla \cdot \mathbf{F}
\end{equation*}

If $\mathbf{F}$ is a vector field on $\mathbb{R}^3$, then curl $\mathbf{F}$ is also avector field on $\mathbb{R}^3$. As such, we can compute its divergence. The next theorem shows that the result is 0.

\begin{center}
    \text{If} $\mathbf{F} = P \ \mathbf{i} + Q \ \mathbf{j} + R \ \mathbf{k}$ \text{ is a vector field on } $\mathbb{R}^3 $ \text{ and } $P, Q, $\text{ and } $R $ \text{have continuous second-order partial derivatives, then }
\end{center}

\begin{equation*}
    \text{div curl} \ \mathbf{F} = 0
\end{equation*}

Again, the reason for the name \textit{divergence} can be understood in the context of fluid flow. if $\mathbf{F}(x,y,z)$ is the velocity of a fluid (or gas), the div $\mathbf{F}(x,y,z)$ represents the net rate of change (with respect to time) of the mass of fluid (or gas) flowing from the point $(x,y,z)$ per unit volume. In other words, div $\mathbf{F}(x,y,z)$ measures the tendency of the fluid to diverge from the point $(x,y,z)$. If div $\mathbf{F} = 0$, then $\mathbf{F}$ is said to be \textbf{incompressible}. Another differential operator occurs when we compute the divergence of a gradient vector field $\nabla f$. If $f$ is a function of three variables, we have 

\begin{equation*}
    \text{div}(\nabla f) = \nabla \cdot (\nabla f) = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} + \frac{\partial^2 f} {\partial z^2} 
\end{equation*}

and this expression occurs so often that we abbreviate it as $\nabla^2 f$. The operator

\begin{equation*}
    \nabla^2 = \nabla \cdot \nabla
\end{equation*}

is called the \textbf{Laplace operator} because of its relation to \textbf{Laplace's equation}

\begin{equation*}
    \nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} + \frac{\partial^2 f} {\partial z^2}  = 0
\end{equation*}

We can also apply the Laplace operator $\nabla^2$ to a vector field

\begin{equation*}
    \mathbf{F} = P \ \mathbf{i} + Q \ \mathbf{j} + R \ \mathbf{k}
\end{equation*}

in terms of its components:

\begin{equation*}
    \nabla^2 \mathbf{F} = \nabla^2 P \ \mathbf{i} + \nabla^2 Q \ \mathbf{j} + \nabla^2 R \ \mathbf{k}
\end{equation*}

\subsection{Vector forms of Green's Theorem}

The curl and divergence operators allow us to rewrite Green's Theorem in versions that will be useful in our later work. We suppose that the plane region $D$, its boundary curve $C$, and the functions $P$ and $Q$ satisfy the hypothesis of Green's Theorem. Then we consider the vector field $\mathbf{F} = P \ \mathbf{i} + Q \ \mathbf{j}$. Its line integral is 

\begin{equation*}
    \oint_C \mathbf{F} \cdot d \mathbf{r} = \oint_C P \ dx + Q \ dy
\end{equation*}

and regarding $\mathbf{F}$ as a vector field on $\mathbb{R}^3$ with third component 0, we have 

\begin{equation*}
    \text{curl } \mathbf{F} = \begin{vmatrix}
        \mathbf{i} & \mathbf{j} & \mathbf{k} \\[6pt]
        \frac{\partial }{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\[6pt] 
        P(x,y) & Q(x,y) & 0
    \end{vmatrix} = (\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}) \mathbf{k}
\end{equation*}

Therefore

\begin{equation*}
    (\text{curl } \mathbf{F}) \cdot \mathbf{k} = \bigg( \frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y} \bigg) \mathbf{k} \cdot \mathbf{k} = \frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}
\end{equation*}

and we can now rewrite the equation in Green's Theorem in the vector form 

\begin{equation*}
    \oint_C \mathbf{F} \cdot d \mathbf{r} = \iint\limits_D (\text{curl } \mathbf{F}) \cdot \mathbf{k} \ \mathrm{d} A
\end{equation*}

\newpage
\section{Parametric Surfaces}

So far, we have considered special types of surfaces: cylinders, quadric surfaces, graphs of functions of two variables, and level surfaces of functions of three variables. Here we use vector functions to describe more general surfaces, called \textit{parametric surfaces}, and compute their areas. Then we take the general surface area formula and see how it applies to special surfaces

In much the same way that we describe a space curve by a vector function $\mathbf{r}(t)$ of a single parameter $t$, we can describe a surface by a vector function $\mathbf{r}(u,v)$ of two parameters $u$ and $v$. We suppose

\begin{equation*}
    \mathbf{r}(u,v) = x(u,v) \ \mathbf{i} + y(u,v) \ \mathbf{j} + z(u,v) \ \mathbf{k}
\end{equation*}

is a vector-valued function defined on a region $D$ in the $uv$-plane so $x$, $y$, and $z$ the component functions of $\mathbf{r}$ are functions of two variables $u$ and $v$ with the domain $D$. the set of all points $(x,y,z)$ in $\mathbb{R}^3$ such that 

\begin{equation*}
    x = x(u,v) \qquad y = y(u,v) \qquad z = z(u,v)
\end{equation*}

and $(u,v)$ varies throughout $D$, is called a \textbf{parametric surface} $S$ and the equations above are called \textbf{parametric equations} of $S$. Each choice of $u$ and $v$ gives a point on $S$; by making all choices, we get all of $S$. In other words, the surface $S$ is traced out by the tip of the position vector $\mathbf{r}(u,v)$ as $(u,v)$ moves throughout the region $D$

\subsection{Tangent Planes}

We now find the tangent plane to a parametric surface $S$ traced out by a vector function 

\begin{equation*}
    \mathbf{r}(u,v) = x(u,v) \ \mathbf{i} + y(u,v) \ \mathbf{j} + z(u,v) \ \mathbf{k}
\end{equation*}

at a point $P_0$ with a position vector $\mathbb{r}(u_0, v_0)$. If we keep $u$ constant by putting $u = u_0$, then $\mathbf{r}(u_0,v)$ becomes a vector function of the single parameter $v$ and defines a grid curve $C_1$ lying on $S$. The tangent vector to $C_1$ and $P_0$ is obtained by taking the partial derivative of $\mathbb{r}$ with respect to $v$: 

\begin{equation*}
    \mathbf{r}_v    = \frac{\partial x}{\partial v}(u_0,v_0) \ \mathbf{i} + \frac{\partial y}{\partial v}(u_0,v_0) \ \mathbf{j} + \frac{\partial z}{\partial v} (u_0, v_0)  \ \mathbf{k}
\end{equation*}

Similarly, if we keep $v$ constant by putting $v = v_0$, we get a grid curve $C_2$ given by $\mathbf{r}(u,v_0)$ that lies on $S$, and its tanget vector and $P_0$ is

\begin{equation*}
    \mathbf{r}_u    = \frac{\partial x}{\partial u}(u_0,v_0) \ \mathbf{i} + \frac{\partial y}{\partial u}(u_0,v_0) \ \mathbf{j} + \frac{\partial z}{\partial u} (u_0, v_0)  \ \mathbf{k}
\end{equation*}

if $r_u \times r_v $ is not $\mathbf{0 }$ then the surface $S$ is called \textbf{smooth} (it has no "corners"). For a smooth surface, the \textbf{tangent plane} is the plane that contains the tangetn vector $r_u$ and $r_v$, and the vector $r_u \times r_v$ is a normal vector to the tangent plane.

\subsection{Surface Area}

Now we define the surface area of a general parametric  surface given by the equation 

\begin{equation*}
    \mathbf{r}(u,v) = x(u,v) \ \mathbf{i} + y(u,v) \ \mathbf{j} + z(u,v) \ \mathbf{k}
\end{equation*}

For simplicity, we start by consider a surface whose parameter domain $D$ is a rectangle, and we divide it into subrectangles $R_{ij}$. Let's choose $(u_i^*, v_i^*)$ to be the lower left corner of $R_{ij}$

blahblah blah ri3manns sun ble gjlfjdjskflsjlkdsklds

so we get the following:

If a smooth parametric surface $S$ is given by the equation 

\begin{equation*}
    \mathbf{r}(u,v) = x(u,v) \ \mathbf{i} + y(u,v) \ \mathbf{j} + z(u,v) \ \mathbf{k} \qquad (u,v) \in D
\end{equation*}

and $S$ is convered just once as $(u,v)$ ranges throughout the parameter domain $D$, then the \textbf{surface area} of $S$ is 

\begin{equation*}
    A(S) = \iint\limits_{D} \rvert \mathbf{r}_u \times \mathbf{r}_v \rvert \ \mathrm{d} A
\end{equation*}

where 

\begin{equation*}
    \mathbf{r}_u = \frac{\partial x}{\partial u} \ \mathbf{i} + \frac{\partial y}{\partial u} \ \mathbf{j} + \frac{\partial z}{ \partial u} \ \mathbf{k} \qquad \mathbf{r}_v = \frac{\partial x}{\partial v} \ \mathbf{i} + \frac{\partial y}{\partial v} \ \mathbf{j} + \frac{\partial z}{ \partial v} \ \mathbf{k}
\end{equation*}

finally done with this section!!!!!



\newpage
\section{Surface Integrals}

The relationship between surface integrals and surface area is much the same as the relationship between line integrals and arc length. Suppose $f$ is a function of three variables whose domains includes a surface $S$. We will define the surface integral of $f$ over $S$ in such a way that, in the case where $f(x,y,z) = 1$, the value of the surface integral is equal to the surface area of $S$. We start with parametric surfaces and then deal with the special case where $S$ is the graph of a function of two variables.

\subsection{Parametric Surfaces}

Suppose that a surface $S$ has a vector equation 

\begin{equation*}
    \mathbf{r}(u,v) = x(u,v) \ \mathbf{i} + y(u,v) \ \mathbf{j} + z(u,v) \ \mathbf{k} \qquad (u,v) \in D
\end{equation*}

We first assume that the parameter domain $D$ is a rectangle and we divide it into the blah blah blah we get 

\begin{equation*}
    \iint\limits_{S} f(x,y,z) \ \mathrm{d}S = \iint\limits_{D} f(\mathbf{r}(u,v)) \rvert \mathbf{r}_u \times \mathbf{r}_v   \rvert \ \mathrm{d}A
\end{equation*}

This should be compared with the formula for a line integral 

\begin{equation*}
    \int_C f(x,y,z) \ ds = \int_{a}^{b} f(\mathbf{r}(t)) \rvert \mathbf{r}'(t) \rvert \ dt
\end{equation*}

Observe also that 

\begin{equation*}
    \iint\limits_{S} 1 \ \mathrm{d}S = \iint\limits_{D} \rvert \mathbf{r}_u  \times \mathbf{r}_v  \rvert \ \mathrm{d}A = A(S)
\end{equation*}

this new formula allows is to compute a surface integral by converting it into a double integral over the parameter domain $D$. When using this formula, remember that $f(\mathbf{r}(u,v))$ is evaluated by writing $x = x(u,v)$, $y = y(u,v)$, $z = z(u,v)$ in the formula for $f(x,y,z)$.



\subsection{Graphs of Functions}

Any surface $S$ with equation $z = g(x,y)$ can be regarded as a parametric surface with parametric equations

\begin{equation*}
    x = x \qquad y = y \qquad z = g(x,y)
\end{equation*}

and so we have 

\begin{equation*}
    \mathbf{r}_x = \mathbf{i} + \bigg( \frac{\partial g}{\partial x} \bigg) \mathbf{k} \qquad \mathbf{r}_y = \mathbf{j} + \bigg(  \frac{\partial g}{\partial y}\bigg) \mathbf{k}
\end{equation*}

Thus

\begin{equation*}
    \mathbf{r}_x  \times \mathbf{r}_y = - \frac{\partial g }{\partial x} \ \mathbf{i} - \frac{\partial g}{\partial y} \ \mathbf{j} + \mathbf{k} 
\end{equation*}

and 

\begin{equation*}
    \bigg\rvert \mathbf{r}_x \times \mathbf{r}_y \bigg\rvert = \sqrt{(\frac{\partial z}{\partial x})^2 + (\frac{\partial z}{\partial y})^2 + 1}
\end{equation*}

Therefore, in this case, this formula becomes 

\begin{equation*}
    \iint\limits_{S} f(x,y,z) \ \mathrm{d}S = \iint\limits_{D} f(x,y,g(x,y))\sqrt{(\frac{\partial z}{\partial x})^2 + (\frac{\partial z}{\partial y})^2 + 1} \ \mathrm{d} A
\end{equation*}

Similar formulas apply when it is more conenient to project $S$ onto the $yz$-plane or $xz$-plane. For instance, if $S$ is a surface with equation $y = h(x,z)$ and $D$ is its projection onto the $xz$-plane, then

\begin{equation*}
    \iint\limits_{S} f(x,y,z) \ \mathrm{d}S = \iint\limits_{D} f(x,h(,x,z),z) \sqrt{(\frac{\partial y}{\partial x})^2 + (\frac{\partial y}{\partial z})^2 + 1} \ \mathrm{d}A
\end{equation*}

\subsection{Surface Integrals of Vector Fields}

Suppose that $S$ is an oriented surface with unit normal vector $\mathbf{n}$, and imagine a fluid with density $\rho(x,y,z)$ and velocity field $\mathbf{v}(x,y,z)$ flowing through $S$. (Think of $S$ as an imaginary surface that doesn't impeded the fluid flow like a fishing net across a stream.) Then the rate of flow (mass per unit time) per unit area is $\rho \mathbf{v}$. If we divide $S$ into small patches $S_{ij}$, then $S_{ij}$ is nearly planar and so we can approximate the mass of fluid per unit time crossing $S_{ij}$ in the direction of the normal $\mathbf{n}$ by the quantity

\begin{equation*}
    (\rho \mathbf{v} \cdot \mathbb{n})A(S_{ij})
\end{equation*}

where $\rho, \mathbf{v}, $ and $\mathbf{n}$ are evaluated at some point on $S_{ij}$, By summing these quantities and taking the limit we get, according to the definition from earlier the surface integral of the function $\rho \mathbf{v} \cdot \mathbf{n}$ over $S$:

\begin{equation*}
    \iint\limits_{S} \rho \mathbf{v} \cdot \mathbf{n} \ \mathrm{d}S = \iint\limits_{S} \rho(x,y,z) \mathbf{v}(x,y,z) \cdot \mathbf{n}(x,y,z) \ \mathrm{d}S
\end{equation*}

and this is interpreted physically as the rate of flow through $S$. 

If we write $\mathbf{F} = \rho \mathbf{v}$, then $\mathbf{F}$ is also a vector field on $\mathbb{R}^3$ and the integral from before 

\begin{equation*}
    \iint\limits_{S} \mathbf{F} \cdot \mathbf{n} \ \mathrm{d}S
\end{equation*}

A surface integral of this form occurs frequently in physics, even when $\mathbf{F}$ is not in $\rho \mathbf{v}$, and is called the \textit{surface integral (or flux integral)} of $\mathbf{F}$ over $S$.
\\
If $\mathbf{F}$ is a continuous vector field defined on an oriented surface $S$ with unit normal vector $\mathbf{n}$, then the \textbf{surface integral of F over S} is 

\begin{equation*}
    \iint\limits_{S} \mathbf{F} \cdot \ \mathrm{d}S = \iint\limits_{S} \mathbf{F} \cdot \ \mathbf{n} \ \mathrm{d}S
\end{equation*}

This integral is also called the \textbf{flux} of \textbf{F} across $S$.

In real fucking words, this definition above says that the surface integral of a vector field over $S$ is equal to the surface integral of its normal component over $S$ (as previously defined). 

If $S$ is given by a vector function $\mathbf{r}(u,v)$, then $\mathbf{n}$ is given by $\mathbf{n} = \frac{\mathbf{r}_u \times \mathbf{r}_v}{\rvert \mathbf{r}_u \times \mathbf{r}_v \rvert}$ and from the definition above we have

\begin{equation*}
    \iint\limits_{S} \mathbf{F} \cdot \ \mathrm{d} S = \iint\limits_{S} \mathbf{F}  \cdot \ \frac{\mathbf{r}_u \times \mathbf{r}_v }{\rvert \mathbf{r}_u \times \mathbf{r}_v \rvert} \ \mathrm{d}S
\end{equation*}

this is equal to 

\begin{equation*}
    \iint\limits_{D} [\mathbf{F}(\mathbf{r}(u,v)) \cdot \frac{\mathbf{r}_u \times \mathbf{r}_v }{\rvert \mathbf{r}_u \times \mathbf{r}_v \rvert}] \rvert \mathbf{r}_u \times \mathbf{r}_v \rvert \ \mathrm{d}A
\end{equation*}

where $D$ is the parameter domain. Thus we have

\begin{equation*}
    \iint\limits_{S} \mathbf{F} \cdot \ \mathrm{d}S = \iint\limits_{D} \mathbf{F} \cdot \ (\mathbf{r}_u \times \mathbf{r}_v) \ \mathrm{d}A
\end{equation*}


\end{document}